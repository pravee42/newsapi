{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import requests\r\n",
    "import re\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "import json\r\n",
    "import string\r\n",
    "from datetime import datetime, timedelta"
   ],
   "outputs": [],
   "metadata": {
    "id": "dvUQkCgO2XBD"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import nltk\r\n",
    "nltk.download(\"stopwords\")\r\n",
    "nltk.download(\"punkt\")"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GbOWPfn_wZT7",
    "outputId": "00486907-1691-43d7-c7b2-fd2e2ab73a53"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from nltk.corpus import stopwords\r\n",
    "from nltk.tokenize import word_tokenize\r\n"
   ],
   "outputs": [],
   "metadata": {
    "id": "5qAnPziCwv7e"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "news = []\r\n",
    "img = []\r\n",
    "link = []\r\n",
    "shortnews = []\r\n",
    "cosine = 0"
   ],
   "outputs": [],
   "metadata": {
    "id": "Tul38Ywk2iMv"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def is_similar(x, y):\r\n",
    "  for m in range(0, len(news)):\r\n",
    "    x_list =  word_tokenize(x)\r\n",
    "    y_list = word_tokenize(y)\r\n",
    "    sw = stopwords.words('english')\r\n",
    "    l1 = []\r\n",
    "    l2 = []\r\n",
    "    x_set = {w for w in x_list if not w in sw} \r\n",
    "    y_set = {w for w in y_list if not w in sw}\r\n",
    "    rvector = x_set.union(y_set) \r\n",
    "    for w in rvector:\r\n",
    "      if w in x_set: l1.append(1)\r\n",
    "      else: l1.append(0)\r\n",
    "      if w in y_set: l2.append(1)\r\n",
    "      else: l2.append(0)\r\n",
    "    c = 0\r\n",
    "    for i in range(len(rvector)):\r\n",
    "      c+= l1[i]*l2[i]\r\n",
    "      cosine = c / float((sum(l1)*sum(l2))**0.5)\r\n",
    "    if round(cosine, 3) > 0.19:\r\n",
    "      return round(cosine, 3)\r\n",
    "    else:\r\n",
    "      return 0"
   ],
   "outputs": [],
   "metadata": {
    "id": "-PykexmY09eA"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def printlist(xss):\r\n",
    "  for x in xss:\r\n",
    "    print(x)\r\n",
    "\r\n",
    "pages = 4\r\n",
    "del news\r\n",
    "news = []"
   ],
   "outputs": [],
   "metadata": {
    "id": "e6Mh7a73l3ph"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def getalternate(list1):\r\n",
    "  newlist = []\r\n",
    "  for x in range(0,len(list1),2):\r\n",
    "    try:\r\n",
    "      newlist.append(list1[x])\r\n",
    "    except:\r\n",
    "      continue\r\n",
    "  return newlist"
   ],
   "outputs": [],
   "metadata": {
    "id": "eRI8kAo5C4SS"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i in range(0, pages):\r\n",
    "    URL = \"https://www.indiatoday.in/trending-news?page=\" + str(i)\r\n",
    "    page = requests.get(URL)\r\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\r\n",
    "    results = soup.find(class_=\"view-content\")\r\n",
    "    elements = results.find_all(\"div\", class_=\"catagory-listing\")\r\n",
    "    for j in elements:\r\n",
    "      count = 0\r\n",
    "      headlines = j.find(\"h2\")\r\n",
    "      # news.append(headlines.text)\r\n",
    "      for m in range(len(news)):\r\n",
    "        try:\r\n",
    "          x = is_similar(news[m], headlines.text)\r\n",
    "          count += round(x, 2)\r\n",
    "        except:\r\n",
    "          continue\r\n",
    "      if count <= 2:\r\n",
    "        news.append(headlines.text)\r\n",
    "        image = j.find(\"img\")\r\n",
    "        img.append(image[\"src\"])\r\n",
    "        p = j.find(\"p\")\r\n",
    "        shortnews.append(p.text)\r\n",
    "        link1 = j.find(\"a\")\r\n",
    "        link.append(link1[\"href\"])\r\n",
    "      else:\r\n",
    "        continue\r\n",
    "set_news = set(news)\r\n",
    "set_images = set(img)\r\n",
    "set_short = set(shortnews)\r\n",
    "set_link = set(link)\r\n",
    "new = getalternate(news)\r\n",
    "del news\r\n",
    "news = new\r\n",
    "del new\r\n",
    "printlist(news)            "
   ],
   "outputs": [],
   "metadata": {
    "cellView": "code",
    "id": "vBkTJm8Un1SH"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "URL = \"https://www.thehindu.com/trending/\"\r\n",
    "page = requests.get(URL)\r\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\r\n",
    "results = soup.find(class_=\"ajaxFilter trending \")\r\n",
    "elements = results.find_all(\"div\", class_=\"story-card\")\r\n",
    "news = []\r\n",
    "link = []\r\n",
    "for j in elements:\r\n",
    "  news.append(j.find(\"a\").text.strip())\r\n",
    "  l = j.find(\"a\")\r\n",
    "  print(l)\r\n",
    "  # link.append(l['href'])\r\n",
    "printlist(news)"
   ],
   "outputs": [],
   "metadata": {
    "id": "Bl2Bt6LaHWi1"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " **Sports** **News** "
   ],
   "metadata": {
    "id": "fMm6hsOtyzTb"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import requests\r\n",
    "import re\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "import json\r\n",
    "import string"
   ],
   "outputs": [],
   "metadata": {
    "id": "7tASxGL-VHTr"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# URL = \"https://news.google.com/search?q=sports&hl=en-IN&gl=IN&ceid=IN%3Aen\"\r\n",
    "URL =\"https://news.google.com/topics/CAAqKggKIiRDQkFTRlFvSUwyMHZNRFp1ZEdvU0JXVnVMVWRDR2dKSlRpZ0FQAQ?hl=en-IN&gl=IN&ceid=IN%3Aen\"\r\n",
    "page = requests.get(URL)\r\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\r\n",
    "# results = soup.find(class_=\"lBwEZb BL5WZb xP6mwf\")\r\n",
    "results = soup.find(class_=\"lBwEZb BL5WZb GndZbb\")\r\n",
    "# elements = results.find_all(\"div\", class_=\"NiLAwe y6IFtc R7GTQ keNKEd j7vNaf nID9nc\")\r\n",
    "elements = results.find_all(\"div\", class_=\"DBQmFf NclIid BL5WZb Oc0wGc xP6mwf j7vNaf\")\r\n",
    "news = []\r\n",
    "link = []\r\n",
    "image = []\r\n",
    "for j in elements:\r\n",
    "  news.append(j.find(\"h3\").text)\r\n",
    "  link1 = j.find(\"a\")['href']\r\n",
    "  link1 = \"https://news.google.com\" + link1[1:]\r\n",
    "  link.append(link1)\r\n",
    "  # image.append(j.find(\"img\", class_=\"tvs3Id QwxBBf\")[\"src\"])\r\n",
    "  try:\r\n",
    "    image.append(j.find(\"img\", class_=\"tvs3Id QwxBBf\")[\"src\"])\r\n",
    "  except:\r\n",
    "    image.append(\"https://th.bing.com/th/id/OIP.Bog_Pg2r3w4-dm6LBjQT-gHaFu?w=230&h=180&c=7&r=0&o=5&pid=1.7\")\r\n",
    "\r\n",
    "\r\n",
    "x = [{'news': a, 'image': s, 'link': t} for a, s, t in zip(news, image, link)]\r\n",
    "for x in x:\r\n",
    "  print(x)"
   ],
   "outputs": [],
   "metadata": {
    "id": "7vpU4aqxVIxv"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sports News Tamil\n"
   ],
   "metadata": {
    "id": "tStwA5MpDrjO"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import requests\r\n",
    "import re\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "import json\r\n",
    "import string"
   ],
   "outputs": [],
   "metadata": {
    "id": "VIKgQb05DvNa"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "URL = \"https://news.google.com/topics/CAAqJggKIiBDQkFTRWdvSUwyMHZNRFp1ZEdvU0FuUmhHZ0pKVGlnQVAB?hl=ta&gl=IN&ceid=IN%3Ata\"\r\n",
    "page = requests.get(URL)\r\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\r\n",
    "results = soup.find(class_=\"lBwEZb BL5WZb GndZbb\")\r\n",
    "elements = results.find_all(\"div\", class_=\"DBQmFf NclIid BL5WZb Oc0wGc xP6mwf j7vNaf\")\r\n",
    "news = []\r\n",
    "link = []\r\n",
    "image = []\r\n",
    "for j in elements:\r\n",
    "  news.append(j.find(\"h3\").text)\r\n",
    "  link1 = j.find(\"a\")['href']\r\n",
    "  link1 = \"https://news.google.com\" + link1[1:]\r\n",
    "  link.append(link1)\r\n",
    "  image.append(j.find(\"img\", class_=\"tvs3Id QwxBBf\")[\"src\"])\r\n",
    "\r\n",
    "x = [{'news': a, 'image': s, 'link': t} for a, s, t in zip(news, image, link)]\r\n",
    "for x in x:\r\n",
    "  print(x)"
   ],
   "outputs": [],
   "metadata": {
    "cellView": "code",
    "id": "bl1QVG_8EJOF"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TOP STORIES"
   ],
   "metadata": {
    "id": "j09QAQ4YRxnl"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import requests\r\n",
    "import re\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "import json\r\n",
    "import string"
   ],
   "outputs": [],
   "metadata": {
    "id": "FY24f3qYRzyl"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "URL = \"https://www.msn.com/en-in/news/india\"\r\n",
    "page = requests.get(URL)\r\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\r\n",
    "print(soup)\r\n",
    "results = soup.find(id=\"eventhubriversection1\")\r\n",
    "print(results)\r\n",
    "elements = results.find_all(class_=\"rc-item-js rc-item show\")\r\n",
    "news = []\r\n",
    "link = []\r\n",
    "image = []\r\n",
    "shortnews = []\r\n",
    "for j in elements:\r\n",
    "  news.append(j.find(\"h3\").text)\r\n",
    "  link1 = j.find(\"a\", class_=\"contentlink\")['href']\r\n",
    "  link1 = \"https://www.msn.com/\" + link1[0:]\r\n",
    "  link.append(link1)\r\n",
    "  image.append(j.find(\"img\", class_=\"loaded\")[\"src\"])\r\n",
    "  shortnews.append(j.find(\"p\", class_=\"show\").text)\r\n",
    "\r\n",
    "print(shortnews)\r\n",
    "\r\n",
    "x = [{'news': a, 'image': s, 'link': t} for a, s, t in zip(news, image, link)]\r\n",
    "for x in x:\r\n",
    "  print(x)"
   ],
   "outputs": [],
   "metadata": {
    "id": "4e7Sjh5wSDKG"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "MSN API [link text](https://api.msn.com:443/msn/Feed/me?$top=25&delta=True&session=0f59725e-35f8-4d6f-82d6-cabddf1f701b&contentType=article,video,slideshow,webcontent,content360&queryType=myfeed&ocid=msftnews-msnews-feeds&apikey=0QfOX3Vn51YCzitbLaRkTTBadtWpgTN8NZLW0C1SEM&scn=ANON&activityId=31398FB3-7E4F-45C0-B40D-3BC5B5C64F88&responseSchema=flatview&market=en-in&fdhead=1s-bing-news,1s-br30min,1s-ffw-randflt,1s-remotecompact,1s-winauthservice,1s-xfeed-watch,prg-1sw-2extrarow,prg-1sw-h5ctrl,prg-1sw-icon2,prg-1sw-setcogt,prg-1sw-spmt4,prg-1sw-weabtnarrow,prg-1sw-wosa-t,prg-1sw-wosauth,prg-adspeek,prg-anon-osauth,prg-antp1sauth,prg-brandupntp,prg-brandupwhp,prg-corec,prg-cr-na,prg-ctr-wx5,prg-edge-osauth,prg-en-coinf,prg-en-coreclaim,prg-entdash,prg-entdsh-rf2,prg-entwpor-r4c,prg-fin-invest1,prg-hub-stagingc,prg-imghovc,prg-lintog,prg-osanon3-t,prg-r-fground,prg-sidebar-lt,prg-v-bkplt1,prg-wea-unit,prg-whp-noanimat,prg-winheaddyn8,prg-wpo-entd1-r2,prg-wpo-entdens1,prg-wpo-hpolypc,prg-wpo-ntr2,prg-wpo-rech25t,prg-wpo-sdinctl,prg-wpo-tphour&timeOut=1000&WrapOData=false&DisableTypeSerialization=true)"
   ],
   "metadata": {
    "id": "l9rs7-yjYW2e"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "MSN API NEW [link text](https://api.msn.com/msn/Feed?$top=21&$skip=21&contentType=article,video,slideshow&Ids=Y_ad7de8f0-53ed-41e0-bb86-86fb0bb81a4d&queryType=MyFeed&ocid=verticals-feeds&apikey=0QfOX3Vn51YCzitbLaRkTTBadtWpgTN8NZLW0C1SEM&activityId=bc9530d1-6372-43ef-97a8-82589548394a&market=en-in)"
   ],
   "metadata": {
    "id": "wBf-xDWjmwsf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "BXpAj2Oxmz1a"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bussiness Today.in\n",
    "News"
   ],
   "metadata": {
    "id": "PtzRt1BaR7XK"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import requests\r\n",
    "import re\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "import json\r\n",
    "import string"
   ],
   "outputs": [],
   "metadata": {
    "id": "yEPD1vDfSA3B"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "news = []\r\n",
    "link = []\r\n",
    "image = []\r\n",
    "shortnews = []"
   ],
   "outputs": [],
   "metadata": {
    "id": "cj6b1qTPSRDZ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "URL =\"https://news.google.com/topics/CAAqKggKIiRDQkFTRlFvSUwyMHZNRGx6TVdZU0JXVnVMVWRDR2dKSlRpZ0FQAQ?hl=en-IN&gl=IN&ceid=IN%3Aen\"\r\n",
    "page = requests.get(URL)\r\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\r\n",
    "results = soup.find(class_=\"lBwEZb BL5WZb GndZbb\")\r\n",
    "elements = results.find_all(\"div\", class_=\"DBQmFf NclIid BL5WZb Oc0wGc xP6mwf j7vNaf\")\r\n",
    "news = []\r\n",
    "link = []\r\n",
    "image = []\r\n",
    "for j in elements:\r\n",
    "  news.append(j.find(\"h3\").text)\r\n",
    "  link1 = j.find(\"a\")['href']\r\n",
    "  link1 = \"https://news.google.com\" + link1[1:]\r\n",
    "  link.append(link1)\r\n",
    "  try:\r\n",
    "    image.append(j.find(\"img\", class_=\"tvs3Id QwxBBf\")[\"src\"])\r\n",
    "  except:\r\n",
    "    image.append(\"https://th.bing.com/th/id/OIP.Bog_Pg2r3w4-dm6LBjQT-gHaFu?w=230&h=180&c=7&r=0&o=5&pid=1.7\")\r\n",
    "\r\n",
    "\r\n",
    "x = [{'news': a, 'image': s, 'link': t} for a, s, t in zip(news, image, link)]\r\n",
    "for x in x:\r\n",
    "  print(x)"
   ],
   "outputs": [],
   "metadata": {
    "id": "MvcLUpUOSFKp"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Economy\n"
   ],
   "metadata": {
    "id": "93Gn8K5J_wCA"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "URL =\"https://news.google.com/topics/CAAqKggKIiRDQkFTRlFvSUwyMHZNRGx6TVdZU0JXVnVMVWRDR2dKSlRpZ0FQAQ/sections/CAQiTENCQVNNd29JTDIwdk1EbHpNV1lTQldWdUxVZENHZ0pKVGlJUENBUWFDd29KTDIwdk1HZG1jSE16S2dzU0NTOXRMekJuWm5Cek15Z0EqLggAKioICiIkQ0JBU0ZRb0lMMjB2TURsek1XWVNCV1Z1TFVkQ0dnSkpUaWdBUAFQAQ?hl=en-IN&gl=IN&ceid=IN%3Aen\"\r\n",
    "page = requests.get(URL)\r\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\r\n",
    "results = soup.find(class_=\"lBwEZb BL5WZb GndZbb\")\r\n",
    "elements = results.find_all(\"div\", class_=\"DBQmFf NclIid BL5WZb Oc0wGc xP6mwf j7vNaf\")\r\n",
    "news = []\r\n",
    "link = []\r\n",
    "image = []\r\n",
    "for j in elements:\r\n",
    "  news.append(j.find(\"h3\").text)\r\n",
    "  link1 = j.find(\"a\")['href']\r\n",
    "  link1 = \"https://news.google.com\" + link1[1:]\r\n",
    "  link.append(link1)\r\n",
    "  try:\r\n",
    "    image.append(j.find(\"img\", class_=\"tvs3Id QwxBBf\")[\"src\"])\r\n",
    "  except:\r\n",
    "    image.append(\"https://th.bing.com/th/id/OIP.Bog_Pg2r3w4-dm6LBjQT-gHaFu?w=230&h=180&c=7&r=0&o=5&pid=1.7\")\r\n",
    "\r\n",
    "\r\n",
    "x = [{'news': a, 'image': s, 'link': t} for a, s, t in zip(news, image, link)]\r\n",
    "for x in x:\r\n",
    "  print(x)"
   ],
   "outputs": [],
   "metadata": {
    "id": "5_ickObE_xfo"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Markets"
   ],
   "metadata": {
    "id": "VA4uzAH9AVoR"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "URL =\"https://news.google.com/topics/CAAqKggKIiRDQkFTRlFvSUwyMHZNRGx6TVdZU0JXVnVMVWRDR2dKSlRpZ0FQAQ/sections/CAQiYENCQVNRZ29JTDIwdk1EbHpNV1lTQldWdUxVZENHZ0pKVGlJUENBUWFDd29KTDIwdk1EbDVOSEJ0S2hvS0dBb1VUVUZTUzBWVVUxOVRSVU5VU1U5T1gwNUJUVVVnQVNnQSouCAAqKggKIiRDQkFTRlFvSUwyMHZNRGx6TVdZU0JXVnVMVWRDR2dKSlRpZ0FQAVAB?hl=en-IN&gl=IN&ceid=IN%3Aen\"\r\n",
    "page = requests.get(URL)\r\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\r\n",
    "results = soup.find(class_=\"lBwEZb BL5WZb GndZbb\")\r\n",
    "elements = results.find_all(\"div\", class_=\"NiLAwe y6IFtc R7GTQ keNKEd j7vNaf nID9nc\")\r\n",
    "news = []\r\n",
    "link = []\r\n",
    "image = []\r\n",
    "for j in elements:\r\n",
    "  news.append(j.find(\"h3\").text)\r\n",
    "  link1 = j.find(\"a\")['href']\r\n",
    "  link1 = \"https://news.google.com\" + link1[1:]\r\n",
    "  link.append(link1)\r\n",
    "  try:\r\n",
    "    image.append(j.find(\"img\", class_=\"tvs3Id QwxBBf\")[\"src\"])\r\n",
    "  except:\r\n",
    "    image.append(\"https://th.bing.com/th/id/OIP.Bog_Pg2r3w4-dm6LBjQT-gHaFu?w=230&h=180&c=7&r=0&o=5&pid=1.7\")\r\n",
    "\r\n",
    "\r\n",
    "x = [{'news': a, 'image': s, 'link': t} for a, s, t in zip(news, image, link)]\r\n",
    "for x in x:\r\n",
    "  print(x)"
   ],
   "outputs": [],
   "metadata": {
    "id": "JssjYhj8AXoi"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Enterpurnership"
   ],
   "metadata": {
    "id": "8AYFdZRvBiPS"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "URL =\"https://news.google.com/topics/CAAqKggKIiRDQkFTRlFvSUwyMHZNRGx6TVdZU0JXVnVMVWRDR2dKSlRpZ0FQAQ/sections/CAQiSkNCQVNNUW9JTDIwdk1EbHpNV1lTQldWdUxVZENHZ0pKVGlJT0NBUWFDZ29JTDIwdk1ESnVkM0VxQ2hJSUwyMHZNREp1ZDNFb0FBKi4IACoqCAoiJENCQVNGUW9JTDIwdk1EbHpNV1lTQldWdUxVZENHZ0pKVGlnQVABUAE?hl=en-IN&gl=IN&ceid=IN%3Aen\"\r\n",
    "page = requests.get(URL)\r\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\r\n",
    "results = soup.find(class_=\"lBwEZb BL5WZb GndZbb\")\r\n",
    "elements = results.find_all(\"div\", class_=\"NiLAwe y6IFtc R7GTQ keNKEd j7vNaf nID9nc\")\r\n",
    "news = []\r\n",
    "link = []\r\n",
    "image = []\r\n",
    "for j in elements:\r\n",
    "  news.append(j.find(\"h3\").text)\r\n",
    "  link1 = j.find(\"a\")['href']\r\n",
    "  link1 = \"https://news.google.com\" + link1[1:]\r\n",
    "  link.append(link1)\r\n",
    "  try:\r\n",
    "    image.append(j.find(\"img\", class_=\"tvs3Id QwxBBf\")[\"src\"])\r\n",
    "  except:\r\n",
    "    image.append(\"https://th.bing.com/th/id/OIP.Bog_Pg2r3w4-dm6LBjQT-gHaFu?w=230&h=180&c=7&r=0&o=5&pid=1.7\")\r\n",
    "\r\n",
    "\r\n",
    "x = [{'news': a, 'image': s, 'link': t} for a, s, t in zip(news, image, link)]\r\n",
    "for x in x:\r\n",
    "  print(x)"
   ],
   "outputs": [],
   "metadata": {
    "id": "rG6KwUcFBnqc"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Search News"
   ],
   "metadata": {
    "id": "d74vIHqVFtpM"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "search_value = input(\"Enter the Search Query\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "URL =\"https://news.google.com/search?q=\"+search_value+\"&hl=en-IN&gl=IN&ceid=IN%3Aen\"\r\n",
    "print(URL)\r\n",
    "page = requests.get(URL)\r\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\r\n",
    "results = soup.find(class_=\"lBwEZb BL5WZb xP6mwf\")\r\n",
    "elements = results.find_all(\"div\", class_=\"NiLAwe y6IFtc R7GTQ keNKEd j7vNaf nID9nc\")\r\n",
    "news = []\r\n",
    "link = []\r\n",
    "image = []\r\n",
    "for j in elements:\r\n",
    "  news.append(j.find(\"h3\").text)\r\n",
    "  link1 = j.find(\"a\")['href']\r\n",
    "  link1 = \"https://news.google.com\" + link1[1:]\r\n",
    "  link.append(link1)\r\n",
    "  try:\r\n",
    "    image.append(j.find(\"img\", class_=\"tvs3Id QwxBBf\")[\"src\"])\r\n",
    "  except:\r\n",
    "    image.append(\"https://th.bing.com/th/id/OIP.Bog_Pg2r3w4-dm6LBjQT-gHaFu?w=230&h=180&c=7&r=0&o=5&pid=1.7\")\r\n",
    "\r\n",
    "\r\n",
    "x = [{'news': a, 'image': s, 'link': t} for a, s, t in zip(news, image, link)]\r\n",
    "for x in x:\r\n",
    "  print(x)"
   ],
   "outputs": [],
   "metadata": {
    "id": "J_5RHh1wFvpx",
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Education News"
   ],
   "metadata": {
    "id": "bIYuzrdaZp1v"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import requests\r\n",
    "import re\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "import json\r\n",
    "import string"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "news = []\r\n",
    "link = []\r\n",
    "image = []\r\n",
    "\r\n",
    "for i in range(1,10):\r\n",
    "    URL =\"https://www.ndtv.com/education/exams-news?page=\" + str(i)\r\n",
    "    page = requests.get(URL)\r\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\r\n",
    "    results = soup.find(\"div\", class_=\"articles\")\r\n",
    "    elements = results.find_all(\"article\")\r\n",
    "\r\n",
    "    for j in elements:\r\n",
    "        try:\r\n",
    "            news.append(j.find(\"a\").text)\r\n",
    "            link1 = j.find(\"a\")['href']\r\n",
    "            link1 = \"https://www.ndtv.com/\" + link1[1:]\r\n",
    "            link.append(link1)\r\n",
    "        except:\r\n",
    "            pass\r\n",
    "        try:\r\n",
    "            image.append(j.find(\"img\", class_=\"lazy\")[\"src\"])\r\n",
    "        except:\r\n",
    "            image.append(\"https://th.bing.com/th/id/OIP.Bog_Pg2r3w4-dm6LBjQT-gHaFu?w=230&h=180&c=7&r=0&o=5&pid=1.7\")\r\n",
    "\r\n",
    "\r\n",
    "x = [{'news': a, 'image': s, 'link': t} for a, s, t in zip(news, image, link)]\r\n",
    "for x in x:\r\n",
    "  print(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### School News"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "news = []\r\n",
    "link = []\r\n",
    "image = []\r\n",
    "\r\n",
    "for i in range(1,10):\r\n",
    "    URL =\"https://www.ndtv.com/education/school-news?page=\" + str(i)\r\n",
    "    page = requests.get(URL)\r\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\r\n",
    "    results = soup.find(\"div\", class_=\"articles\")\r\n",
    "    elements = results.find_all(\"article\")\r\n",
    "\r\n",
    "    for j in elements:\r\n",
    "        try:\r\n",
    "            news.append(j.find(\"a\").text)\r\n",
    "            link1 = j.find(\"a\")['href']\r\n",
    "            link1 = \"https://www.ndtv.com/\" + link1[1:]\r\n",
    "            link.append(link1)\r\n",
    "        except:\r\n",
    "            pass\r\n",
    "        try:\r\n",
    "            image.append(j.find(\"img\", class_=\"lazy\")[\"src\"])\r\n",
    "        except:\r\n",
    "            image.append(\"https://th.bing.com/th/id/OIP.Bog_Pg2r3w4-dm6LBjQT-gHaFu?w=230&h=180&c=7&r=0&o=5&pid=1.7\")\r\n",
    "\r\n",
    "\r\n",
    "x = [{'news': a, 'image': s, 'link': t} for a, s, t in zip(news, image, link)]\r\n",
    "for x in x:\r\n",
    "  print(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "news = []\r\n",
    "link = []\r\n",
    "image = []\r\n",
    "\r\n",
    "for i in range(1,10):\r\n",
    "    URL =\"https://www.ndtv.com/education/campus-news?page=\" + str(i)\r\n",
    "    page = requests.get(URL)\r\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\r\n",
    "    results = soup.find(\"div\", class_=\"articles\")\r\n",
    "    elements = results.find_all(\"article\")\r\n",
    "\r\n",
    "    for j in elements:\r\n",
    "        try:\r\n",
    "            news.append(j.find(\"a\").text)\r\n",
    "            link1 = j.find(\"a\")['href']\r\n",
    "            link1 = \"https://www.ndtv.com/\" + link1[1:]\r\n",
    "            link.append(link1)\r\n",
    "        except:\r\n",
    "            pass\r\n",
    "        try:\r\n",
    "            image.append(j.find(\"img\", class_=\"lazy\")[\"src\"])\r\n",
    "        except:\r\n",
    "            image.append(\"https://th.bing.com/th/id/OIP.Bog_Pg2r3w4-dm6LBjQT-gHaFu?w=230&h=180&c=7&r=0&o=5&pid=1.7\")\r\n",
    "\r\n",
    "\r\n",
    "x = [{'news': a, 'image': s, 'link': t} for a, s, t in zip(news, image, link)]\r\n",
    "for x in x:\r\n",
    "  print(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import requests\r\n",
    "import re\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "import json\r\n",
    "import string"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "URL =\"https://news.google.com/search?q=\"+search_value+\"&hl=en-IN&gl=IN&ceid=IN%3Aen\"\r\n",
    "print(URL)\r\n",
    "page = requests.get(URL)\r\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\r\n",
    "results = soup.find(class_=\"lBwEZb BL5WZb xP6mwf\")\r\n",
    "elements = results.find_all(\"div\", class_=\"NiLAwe y6IFtc R7GTQ keNKEd j7vNaf nID9nc\")\r\n",
    "news = []\r\n",
    "link = []\r\n",
    "image = []\r\n",
    "for j in elements:\r\n",
    "  news.append(j.find(\"h3\").text)\r\n",
    "  link1 = j.find(\"a\")['href']\r\n",
    "  link1 = \"https://news.google.com\" + link1[1:]\r\n",
    "  link.append(link1)\r\n",
    "  try:\r\n",
    "    image.append(j.find(\"img\", class_=\"tvs3Id QwxBBf\")[\"src\"])\r\n",
    "  except:\r\n",
    "    image.append(\"https://th.bing.com/th/id/OIP.Bog_Pg2r3w4-dm6LBjQT-gHaFu?w=230&h=180&c=7&r=0&o=5&pid=1.7\")\r\n",
    "\r\n",
    "\r\n",
    "x = [{'news': a, 'image': s, 'link': t} for a, s, t in zip(news, image, link)]\r\n",
    "for x in x:\r\n",
    "  print(x)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "news api abipravi",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "my-conda-env-kernel",
   "language": "python",
   "name": "my-conda-env-kernel"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}